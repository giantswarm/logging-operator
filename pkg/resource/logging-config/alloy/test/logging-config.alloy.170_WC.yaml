# This file was generated by logging-operator.
# It configures Alloy to be used as a logging agent.
# - configMap is generated from logging.alloy.template and passed as a string
#   here and will be created by Alloy's chart.
# - Alloy runs as a daemonset, with required tolerations in order to scrape logs
#   from every machine in the cluster.
# - Running as root user is required in order to be able to read log files within
#   /var/log/journal and /run/log/journal directories.
# - NODENAME env var is used as additional label for kubernetes_audit logs.
alloy:
  alloy:
    configMap:
      create: true
      content: |-
        remote.kubernetes.secret "credentials" {
        	namespace = "kube-system"
        	name = "alloy-logs"
        }
        
        // Kubernetes pods logs
        loki.source.podlogs "kubernetes_pods" {
        	forward_to      = [loki.relabel.kubernetes_pods.receiver]
        
        	clustering {
        		enabled = true
        	}
        }
        
        loki.relabel "kubernetes_pods" {
        	forward_to      = [loki.process.kubernetes_pods.receiver]
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_controller_name"]
        		regex         = "([0-9a-z-.]+?)(-[0-9a-f]{8,10})?"
        		target_label  = "__tmp_controller_name"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name", "__meta_kubernetes_pod_label_app", "__tmp_controller_name", "__meta_kubernetes_pod_name"]
        		regex         = "^;*([^;]+)(;.*)?$"
        		target_label  = "app"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_instance", "__meta_kubernetes_pod_label_instance"]
        		regex         = "^;*([^;]+)(;.*)?$"
        		target_label  = "instance"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_component", "__meta_kubernetes_pod_label_component"]
        		regex         = "^;*([^;]+)(;.*)?$"
        		target_label  = "component"
        	}
        
        	rule {
        		target_label = "scrape_job"
        		replacement  = "kubernetes-pods"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_node_name"]
        		target_label  = "node"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_namespace"]
        		target_label  = "namespace"
        	}
        
        	rule {
        		source_labels = ["namespace", "app"]
        		separator     = "/"
        		target_label  = "job"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_name"]
        		target_label  = "pod"
        	}
        
        	rule {
        		source_labels = ["__meta_kubernetes_pod_container_name"]
        		target_label  = "container"
        	}
        }
        
        loki.process "kubernetes_pods" {
        	forward_to = [loki.write.default.receiver]
        
        	stage.cri { }
        
        	stage.structured_metadata {
        		values = {
        			"filename" = "",
        			"stream" = "",
        		}
        	}
        
        	stage.label_drop {
        		values = [
        			"filename",
        			"stream",
        		]
        	}
        	// We drop lines that do not have a tenant
        	stage.drop {
        		source = "__tenant_id__"
        		value  = ""
        	}
        }
        
        // journald logs from /run/log/journal
        loki.process "systemd_journal_run" {
        	forward_to = [loki.write.default.receiver]
        
        	stage.json {
        		expressions = {
        			SYSLOG_IDENTIFIER = "SYSLOG_IDENTIFIER",
        		}
        	}
        
        	stage.drop {
        		source = "SYSLOG_IDENTIFIER"
        		value  = "audit"
        	}
        }
        
        discovery.relabel "systemd_journal_run" {
        	targets = []
        
        	rule {
        		source_labels = ["__journal__systemd_unit"]
        		target_label  = "__tmp_systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__journal__systemd_unit", "__journal_syslog_identifier"]
        		regex         = ";(.+)"
        		target_label  = "__tmp_systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__tmp_systemd_unit"]
        		target_label  = "systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__journal__hostname"]
        		target_label  = "node"
        	}
        }
        
        loki.source.journal "systemd_journal_run" {
        	format_as_json = true
        	max_age        = "12h0m0s"
        	path           = "/run/log/journal"
        	relabel_rules  = discovery.relabel.systemd_journal_run.rules
        	forward_to     = [loki.process.systemd_journal_run.receiver]
        	labels         = {
        		scrape_job = "system-logs",
        	}
        }
        
        // journald logs from /var/log/journal
        loki.process "systemd_journal_var" {
        	forward_to = [loki.write.default.receiver]
        
        	stage.json {
        		expressions = {
        			SYSLOG_IDENTIFIER = "SYSLOG_IDENTIFIER",
        		}
        	}
        
        	stage.drop {
        		source = "SYSLOG_IDENTIFIER"
        		value  = "audit"
        	}
        }
        
        discovery.relabel "systemd_journal_var" {
        	targets = []
        
        	rule {
        		source_labels = ["__journal__systemd_unit"]
        		target_label  = "__tmp_systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__journal__systemd_unit", "__journal_syslog_identifier"]
        		regex         = ";(.+)"
        		target_label  = "__tmp_systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__tmp_systemd_unit"]
        		target_label  = "systemd_unit"
        	}
        
        	rule {
        		source_labels = ["__journal__hostname"]
        		target_label  = "node"
        	}
        }
        
        loki.source.journal "systemd_journal_var" {
        	format_as_json = true
        	max_age        = "12h0m0s"
        	path           = "/var/log/journal"
        	relabel_rules  = discovery.relabel.systemd_journal_var.rules
        	forward_to     = [loki.process.systemd_journal_var.receiver]
        	labels         = {
        		scrape_job = "system-logs",
        	}
        }
        
        // Kubernetes API server audit logs
        local.file_match "kubernetes_audit" {
        	path_targets = [{
        		__address__ = "localhost",
        		__path__    = "/var/log/apiserver/audit.log",
        		node   = coalesce(env("NODENAME"), "unknown"),
        		scrape_job  = "audit-logs",
        	}]
        }
        
        loki.process "kubernetes_audit" {
        	forward_to = [loki.write.default.receiver]
        
        	stage.json {
        		expressions = {
        			objectRef = "objectRef",
        		}
        	}
        
        	stage.json {
        		expressions = {
        			namespace = "namespace",
        			resource  = "resource",
        		}
        		source = "objectRef"
        	}
        
        	stage.structured_metadata {
        		values = {
        			"resource" = "",
        			"filename" = "",
        		}
        	}
        
        	stage.label_drop {
        		values = [
        			"filename",
        		]
        	}
        
        	stage.labels {
        		values = {
        			namespace = "",
        		}
        	}
        }
        
        loki.source.file "kubernetes_audit" {
        	targets               = local.file_match.kubernetes_audit.targets
        	forward_to            = [loki.process.kubernetes_audit.receiver]
        	legacy_positions_file = "/run/promtail/positions.yaml"
        }
        
        // Loki target configuration
        loki.write "default" {
        	endpoint {
        		url                = nonsensitive(remote.kubernetes.secret.credentials.data["logging-url"])
        		max_backoff_period = "10m"
        		tenant_id          = nonsensitive(remote.kubernetes.secret.credentials.data["logging-tenant-id"])
        
        		basic_auth {
        			username = nonsensitive(remote.kubernetes.secret.credentials.data["logging-username"])
        			password = remote.kubernetes.secret.credentials.data["logging-password"]
        		}
        
        		tls_config {
        			insecure_skip_verify = false
        		}
        	}
        	external_labels = {
        		cluster_id   = "test-cluster",
        		installation = "test-installation",
        	}
        }
        
        logging {
        	level  = "warn"
        	format = "logfmt"
        }
        
    clustering:
      enabled: true
      name: alloy-logs
    extraEnv:
    - name: NODENAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    mounts:
      varlog: true
      dockercontainers: true
      extra:
      - name: runlogjournal
        mountPath: /run/log/journal
        readOnly: true
      # This is needed to allow alloy to create files when using readOnlyRootFilesystem
      - name: alloy-tmp
        mountPath: /tmp/alloy
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      runAsUser: 0
      runAsGroup: 0
      runAsNonRoot: false
      seccompProfile:
        type: RuntimeDefault
  controller:
    type: daemonset
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    volumes:
      extra:
      - name: runlogjournal
        hostPath:
          path: /run/log/journal
      - name: alloy-tmp
        emptyDir: {}
verticalPodAutoscaler:
  # -- Creates a VerticalPodAutoscaler for the daemonset
  enabled: true
podLogs:
- name: default-namespaces
  namespace: kube-system
  spec:
    selector: {}
    namespaceSelector:
      matchExpressions:
      - key: kubernetes.io/metadata.name
        operator: In
        values:
        - test-selector
    relabelings:
    - action: replace
      targetLabel: "__tenant_id__"
      replacement: "giantswarm"
